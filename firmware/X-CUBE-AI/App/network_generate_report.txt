ST Edge AI Core v2.2.0-20266 2adc00962
Created date          : 2025-12-12 19:32:28
Parameters            : generate --target stm32l4 --name network -m /home/bohdan/code/poc/human-activity-recognition/stm32-ai-activity-tracker/firmware/resources/trained-models/realworld-dataset/wl-96-overlap-75-joint-lying-sitting-standing/wl-96-overlap-75-joint-lying-sitting-standing-quantized.tflite --compression none --verbosity 1 --workspace /tmp/mxAI_workspace460042087419514637757367468293387 --output /home/bohdan/.stm32cubemx/network_output

Exec/report summary (generate)
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
model file         :   /home/bohdan/code/poc/human-activity-recognition/stm32-ai-activity-tracker/firmware/resources/trained-models/realworld-dataset/wl-96-overlap-75-joint-lying-sitting-standing/wl-96-overlap-75-joint-lying-sitting-standing-quantized.tflite   
type               :   tflite                                                                                                                                                                                                                                        
c_name             :   network                                                                                                                                                                                                                                       
compression        :   none                                                                                                                                                                                                                                          
options            :   allocate-inputs, allocate-outputs                                                                                                                                                                                                             
optimization       :   balanced                                                                                                                                                                                                                                      
target/series      :   stm32l4                                                                                                                                                                                                                                       
workspace dir      :   /tmp/mxAI_workspace460042087419514637757367468293387                                                                                                                                                                                          
output dir         :   /home/bohdan/.stm32cubemx/network_output                                                                                                                                                                                                      
model_fmt          :   ss/sa per channel                                                                                                                                                                                                                             
model_name         :   wl96overlap75jointlyingsittingstandingquantized                                                                                                                                                                                               
model_hash         :   0xa6d58b4820c67477c0c94b167e56146b                                                                                                                                                                                                            
params #           :   36,075 items (35.99 KiB)                                                                                                                                                                                                                      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
input 1/1          :   'serving_default_input_layer0', int8(1x96x3), 288 Bytes, QLinear(0.054216988,7,int8), activations                                                                                                                                             
output 1/1         :   'nl_21', int8(1x5), 5 Bytes, QLinear(0.003906250,-128,int8), activations                                                                                                                                                                      
macc               :   1,234,000                                                                                                                                                                                                                                     
weights (ro)       :   36,860 B (36.00 KiB) (1 segment) / -107,440(-74.5%) vs float model                                                                                                                                                                            
activations (rw)   :   13,760 B (13.44 KiB) (1 segment) *                                                                                                                                                                                                            
ram (total)        :   13,760 B (13.44 KiB) = 13,760 + 0 + 0                                                                                                                                                                                                         
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(*) 'input'/'output' buffers are allocated in the activations buffer

Model name - wl96overlap75jointlyingsittingstandingquantized
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
m_id   layer (type,original)                      oshape                param/size           macc                   connected to   | c_size          c_macc            c_type                 
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
0      serving_default_input_layer0 (Input, )     [b:1,h:96,c:3]                                                                   | +3(+100.0%)     +288(+100.0%)     Eltwise/mul_[0]        
       tfl_pseudo_qconst15 (Placeholder, )        [b:3]                 3/3                                                        | -3(-100.0%)                       
       eltwise_0 (Eltwise, MUL)                   [b:1,h:96,c:3]                              288   serving_default_input_layer0   |                 -288(-100.0%)     
                                                                                                             tfl_pseudo_qconst15   | 
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
1      tfl_pseudo_qconst14 (Placeholder, )        [b:3]                 3/3                                                        |                 +288(+100.0%)     Eltwise/add_[1]        
       eltwise_1 (Eltwise, ADD)                   [b:1,h:96,c:3]                              288                      eltwise_0   |                 -288(-100.0%)     
                                                                                                             tfl_pseudo_qconst14   | 
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
2      reshape_2 (Reshape, EXPAND_DIMS)           [b:1,h:1,w:96,c:3]                                                   eltwise_1   |                                   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
3      conv2d_3 (Conv2D, CONV_2D)                 [b:1,h:1,w:92,c:32]   512/608            44,192                      reshape_2   |                                   Conv2D_[2]             
       nl_3_nl (Nonlinearity, CONV_2D)            [b:1,h:1,w:92,c:32]                       2,944                       conv2d_3   |                 -2,944(-100.0%)   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
4      reshape_4 (Reshape, RESHAPE)               [b:1,h:92,c:32]                                                        nl_3_nl   |                                   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
5      reshape_5 (Reshape, EXPAND_DIMS)           [b:1,h:1,w:92,c:32]                                                  reshape_4   |                                   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
6      pool_6 (Pool, MAX_POOL_2D)                 [b:1,h:1,w:46,c:32]                       2,944                      reshape_5   |                                   Pool_[3]               
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
7      tfl_pseudo_qconst11 (Placeholder, )        [b:32]                32/32                                                      |                 +1,472(+100.0%)   Eltwise/mul_[4]        
       eltwise_7 (Eltwise, MUL)                   [b:1,h:1,w:46,c:32]                       1,472                         pool_6   |                 -1,472(-100.0%)   
                                                                                                             tfl_pseudo_qconst11   | 
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
8      tfl_pseudo_qconst10 (Placeholder, )        [b:32]                32/32                                                      |                 +1,472(+100.0%)   Eltwise/add_[5]        
       eltwise_8 (Eltwise, ADD)                   [b:1,h:1,w:46,c:32]                       1,472                      eltwise_7   |                 -1,472(-100.0%)   
                                                                                                             tfl_pseudo_qconst10   | 
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
9      reshape_9 (Reshape, RESHAPE)               [b:1,h:46,c:32]                                                      eltwise_8   |                                   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
10     reshape_10 (Reshape, EXPAND_DIMS)          [b:1,h:1,w:46,c:32]                                                  reshape_9   |                                   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
11     conv2d_11 (Conv2D, CONV_2D)                [b:1,h:1,w:42,c:64]   10,304/10,496     430,144                     reshape_10   |                                   Conv2D_[6]             
       nl_11_nl (Nonlinearity, CONV_2D)           [b:1,h:1,w:42,c:64]                       2,688                      conv2d_11   |                 -2,688(-100.0%)   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
12     tfl_pseudo_qconst7 (Placeholder, )         [b:64]                64/64                                                      |                 +2,688(+100.0%)   Eltwise/mul_[7]        
       eltwise_12 (Eltwise, MUL)                  [b:1,h:1,w:42,c:64]                       2,688                       nl_11_nl   |                 -2,688(-100.0%)   
                                                                                                              tfl_pseudo_qconst7   | 
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
13     tfl_pseudo_qconst6 (Placeholder, )         [b:64]                64/64                                                      |                 +2,688(+100.0%)   Eltwise/add_[8]        
       eltwise_13 (Eltwise, ADD)                  [b:1,h:1,w:42,c:64]                       2,688                     eltwise_12   |                 -2,688(-100.0%)   
                                                                                                              tfl_pseudo_qconst6   | 
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
14     reshape_14 (Reshape, RESHAPE)              [b:1,h:42,c:64]                                                     eltwise_13   |                                   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
15     reshape_15 (Reshape, EXPAND_DIMS)          [b:1,h:1,w:42,c:64]                                                 reshape_14   |                                   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
16     conv2d_16 (Conv2D, CONV_2D)                [b:1,h:1,w:40,c:96]   18,528/18,816     737,376                     reshape_15   |                                   Conv2D_[9]             
       nl_16_nl (Nonlinearity, CONV_2D)           [b:1,h:1,w:40,c:96]                       3,840                      conv2d_16   |                 -3,840(-100.0%)   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
17     reshape_17 (Reshape, RESHAPE)              [b:1,h:40,c:96]                                                       nl_16_nl   |                                   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
18     pool_18 (Pool, MEAN)                       [b:1,h:1,c:96]                            3,840                     reshape_17   |                                   Pool_[10]              
       reshape_18_reshape (Reshape, MEAN)         [b:1,c:96]                                                             pool_18   |                                   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
19     tfl_pseudo_qconst3 (Placeholder, )         [b:64,c:96]           6,144/6,144                                                | +256(+4.2%)     +6,208(+100.0%)   Dense_[11]             
       tfl_pseudo_qconst2 (Placeholder, )         [b:64]                64/256                                                     | -256(-100.0%)                     
       gemm_19 (Gemm, FULLY_CONNECTED)            [b:1,c:64]                                6,208             reshape_18_reshape   |                 -6,208(-100.0%)   
                                                                                                              tfl_pseudo_qconst3   | 
                                                                                                              tfl_pseudo_qconst2   | 
       nl_19_nl (Nonlinearity, FULLY_CONNECTED)   [b:1,c:64]                                   64                        gemm_19   |                 -64(-100.0%)      
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
20     tfl_pseudo_qconst1 (Placeholder, )         [b:5,c:64]            320/320                                                    | +20(+6.2%)      +325(+100.0%)     Dense_[12]             
       tfl_pseudo_qconst (Placeholder, )          [b:5]                 5/20                                                       | -20(-100.0%)                      
       gemm_20 (Gemm, FULLY_CONNECTED)            [b:1,c:5]                                   325                       nl_19_nl   |                 -325(-100.0%)     
                                                                                                              tfl_pseudo_qconst1   | 
                                                                                                               tfl_pseudo_qconst   | 
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
21     nl_21 (Nonlinearity, SOFTMAX)              [b:1,c:5]                                    75                        gemm_20   |                                   Nonlinearity_[o][13]   
------ ------------------------------------------ --------------------- --------------- --------- ------------------------------ --- --------------- ----------------- ---------------------- 
model/c-model: macc=1,243,536/1,234,000 -9,536(-0.8%) weights=36,858/36,860 +2(+0.0%) activations=--/13,760 io=--/0



Generated C-graph summary
------------------------------------------------------------------------------------------------------------------------
model name            : wl96overlap75jointlyingsittingstandingquantized
c-name                : network
c-node #              : 14
c-array #             : 37
activations size      : 13760 (1 segment)
weights size          : 36860 (1 segment)
macc                  : 1234000
inputs                : ['serving_default_input_layer0_output']
outputs               : ['nl_21_output']

C-Arrays (37)
------ ------------------------------------- ------------- ------------------------- ----------- --------- 
c_id   name (*_array)                        item/size     domain/mem-pool           c-type      comment   
------ ------------------------------------- ------------- ------------------------- ----------- --------- 
0      conv2d_11_bias                        64/256        weights/weights           const s32             
1      conv2d_11_output                      2688/2688     activations/**default**   s8                    
2      conv2d_11_scratch0                    6656/6656     activations/**default**   s8                    
3      conv2d_11_weights                     10240/10240   weights/weights           const s8              
4      conv2d_16_bias                        96/384        weights/weights           const s32             
5      conv2d_16_output                      3840/3840     activations/**default**   s8                    
6      conv2d_16_scratch0                    7232/7232     activations/**default**   s8                    
7      conv2d_16_weights                     18432/18432   weights/weights           const s8              
8      conv2d_3_bias                         32/128        weights/weights           const s32             
9      conv2d_3_output                       2944/2944     activations/**default**   s8                    
10     conv2d_3_scratch0                     1468/1468     activations/**default**   s8                    
11     conv2d_3_weights                      480/480       weights/weights           const s8              
12     eltwise_0_output                      288/288       activations/**default**   s8                    
13     eltwise_12_output                     2688/2688     activations/**default**   s8                    
14     eltwise_13_output                     2688/2688     activations/**default**   s8                    
15     eltwise_1_output                      288/288       activations/**default**   s8                    
16     eltwise_7_output                      1472/1472     activations/**default**   s8                    
17     eltwise_8_output                      1472/1472     activations/**default**   s8                    
18     gemm_19_bias                          64/256        weights/weights           const s32             
19     gemm_19_output                        64/64         activations/**default**   s8                    
20     gemm_19_scratch0                      416/832       activations/**default**   s16                   
21     gemm_19_weights                       6144/6144     weights/weights           const s8              
22     gemm_20_bias                          5/20          weights/weights           const s32             
23     gemm_20_output                        5/5           activations/**default**   s8                    
24     gemm_20_scratch0                      89/178        activations/**default**   s16                   
25     gemm_20_weights                       320/320       weights/weights           const s8              
26     nl_21_output                          5/5           activations/**default**   s8          /output   
27     nl_21_scratch0                        248/992       activations/**default**   s32                   
28     pool_18_output                        96/96         activations/**default**   s8                    
29     pool_6_output                         1472/1472     activations/**default**   s8                    
30     serving_default_input_layer0_output   288/288       activations/**default**   s8          /input    
31     tfl_pseudo_qconst10_4D                32/32         weights/weights           const s8              
32     tfl_pseudo_qconst11_4D                32/32         weights/weights           const s8              
33     tfl_pseudo_qconst14_3D                3/3           weights/weights           const s8              
34     tfl_pseudo_qconst15_3D                3/3           weights/weights           const s8              
35     tfl_pseudo_qconst6_4D                 64/64         weights/weights           const s8              
36     tfl_pseudo_qconst7_4D                 64/64         weights/weights           const s8              
------ ------------------------------------- ------------- ------------------------- ----------- --------- 

C-Layers (14)
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
c_id   name (*_layer)   id   layer_type      macc     rom     tensors                                  shape (array id)       
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
0      eltwise_0        0    Eltwise/mul     288      3       I: serving_default_input_layer0_output   int8(1x96x3) (30)      
                                                              W: tfl_pseudo_qconst15_3D                int8(1x3) (34)         
                                                              O: eltwise_0_output                      int8(1x96x3) (12)      
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
1      eltwise_1        1    Eltwise/add     288      3       I: eltwise_0_output                      int8(1x96x3) (12)      
                                                              W: tfl_pseudo_qconst14_3D                int8(1x3) (33)         
                                                              O: eltwise_1_output                      int8(1x96x3) (15)      
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
2      conv2d_3         3    Conv2D          44192    608     I: eltwise_1_output                      int8(1x96x3) (15)      
                                                              S: conv2d_3_scratch0                                            
                                                              W: conv2d_3_weights                      int8(32x1x5x3) (11)    
                                                              W: conv2d_3_bias                         int32(32) (8)          
                                                              O: conv2d_3_output                       int8(1x1x92x32) (9)    
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
3      pool_6           6    Pool            2944     0       I: conv2d_3_output                       int8(1x1x92x32) (9)    
                                                              O: pool_6_output                         int8(1x1x46x32) (29)   
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
4      eltwise_7        7    Eltwise/mul     1472     32      I: pool_6_output                         int8(1x1x46x32) (29)   
                                                              W: tfl_pseudo_qconst11_4D                int8(1x1x32) (32)      
                                                              O: eltwise_7_output                      int8(1x1x46x32) (16)   
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
5      eltwise_8        8    Eltwise/add     1472     32      I: eltwise_7_output                      int8(1x1x46x32) (16)   
                                                              W: tfl_pseudo_qconst10_4D                int8(1x1x32) (31)      
                                                              O: eltwise_8_output                      int8(1x1x46x32) (17)   
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
6      conv2d_11        11   Conv2D          430144   10496   I: eltwise_8_output                      int8(1x1x46x32) (17)   
                                                              S: conv2d_11_scratch0                                           
                                                              W: conv2d_11_weights                     int8(64x1x5x32) (3)    
                                                              W: conv2d_11_bias                        int32(64) (0)          
                                                              O: conv2d_11_output                      int8(1x1x42x64) (1)    
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
7      eltwise_12       12   Eltwise/mul     2688     64      I: conv2d_11_output                      int8(1x1x42x64) (1)    
                                                              W: tfl_pseudo_qconst7_4D                 int8(1x1x64) (36)      
                                                              O: eltwise_12_output                     int8(1x1x42x64) (13)   
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
8      eltwise_13       13   Eltwise/add     2688     64      I: eltwise_12_output                     int8(1x1x42x64) (13)   
                                                              W: tfl_pseudo_qconst6_4D                 int8(1x1x64) (35)      
                                                              O: eltwise_13_output                     int8(1x1x42x64) (14)   
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
9      conv2d_16        16   Conv2D          737376   18816   I: eltwise_13_output                     int8(1x1x42x64) (14)   
                                                              S: conv2d_16_scratch0                                           
                                                              W: conv2d_16_weights                     int8(96x1x3x64) (7)    
                                                              W: conv2d_16_bias                        int32(96) (4)          
                                                              O: conv2d_16_output                      int8(1x1x40x96) (5)    
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
10     pool_18          18   Pool            3840     0       I: conv2d_16_output                      int8(1x1x40x96) (5)    
                                                              O: pool_18_output                        int8(1x1x96) (28)      
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
11     gemm_19          19   Dense           6208     6400    I: pool_18_output                        int8(1x1x96) (28)      
                                                              S: gemm_19_scratch0                                             
                                                              W: gemm_19_weights                       int8(64x96) (21)       
                                                              W: gemm_19_bias                          int32(64) (18)         
                                                              O: gemm_19_output                        int8(1x64) (19)        
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
12     gemm_20          20   Dense           325      340     I: gemm_19_output                        int8(1x64) (19)        
                                                              S: gemm_20_scratch0                                             
                                                              W: gemm_20_weights                       int8(5x64) (25)        
                                                              W: gemm_20_bias                          int32(5) (22)          
                                                              O: gemm_20_output                        int8(1x5) (23)         
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 
13     nl_21            21   Nonlinearity    75       0       I: gemm_20_output                        int8(1x5) (23)         
                                                              S: nl_21_scratch0                                               
                                                              O: nl_21_output                          int8(1x5) (26)         
------ ---------------- ---- --------------- -------- ------- ---------------------------------------- ---------------------- 



Number of operations per c-layer
------- ------ -------------------------- ----------- ------------ 
c_id    m_id   name (type)                        #op         type 
------- ------ -------------------------- ----------- ------------ 
0       0      eltwise_0 (Eltwise/mul)            288     op_s8_s8 
1       1      eltwise_1 (Eltwise/add)            288     op_s8_s8 
2       3      conv2d_3 (Conv2D)               44,192   smul_s8_s8 
3       6      pool_6 (Pool)                    2,944   smul_s8_s8 
4       7      eltwise_7 (Eltwise/mul)          1,472     op_s8_s8 
5       8      eltwise_8 (Eltwise/add)          1,472     op_s8_s8 
6       11     conv2d_11 (Conv2D)             430,144   smul_s8_s8 
7       12     eltwise_12 (Eltwise/mul)         2,688     op_s8_s8 
8       13     eltwise_13 (Eltwise/add)         2,688     op_s8_s8 
9       16     conv2d_16 (Conv2D)             737,376   smul_s8_s8 
10      18     pool_18 (Pool)                   3,840   smul_s8_s8 
11      19     gemm_19 (Dense)                  6,208   smul_s8_s8 
12      20     gemm_20 (Dense)                    325   smul_s8_s8 
13      21     nl_21 (Nonlinearity)                75     op_s8_s8 
------- ------ -------------------------- ----------- ------------ 
total                                       1,234,000 

Number of operation types
---------------- ----------- ----------- 
operation type             #           % 
---------------- ----------- ----------- 
op_s8_s8               8,971        0.7% 
smul_s8_s8         1,225,029       99.3% 

Complexity report (model)
------ ------------------------------ ------------------------- ------------------------- ------ 
m_id   name                           c_macc                    c_rom                     c_id   
------ ------------------------------ ------------------------- ------------------------- ------ 
0      serving_default_input_layer0   |                  0.0%   |                  0.0%   [0]    
1      tfl_pseudo_qconst14            |                  0.0%   |                  0.0%   [1]    
3      conv2d_3                       |                  3.6%   |                  1.6%   [2]    
6      pool_6                         |                  0.2%   |                  0.0%   [3]    
7      tfl_pseudo_qconst11            |                  0.1%   |                  0.1%   [4]    
8      tfl_pseudo_qconst10            |                  0.1%   |                  0.1%   [5]    
11     conv2d_11                      |||||||||         34.9%   |||||||||         28.5%   [6]    
12     tfl_pseudo_qconst7             |                  0.2%   |                  0.2%   [7]    
13     tfl_pseudo_qconst6             |                  0.2%   |                  0.2%   [8]    
16     conv2d_16                      ||||||||||||||||  59.8%   ||||||||||||||||  51.0%   [9]    
18     pool_18                        |                  0.3%   |                  0.0%   [10]   
19     tfl_pseudo_qconst3             |                  0.5%   ||||||            17.4%   [11]   
20     tfl_pseudo_qconst1             |                  0.0%   |                  0.9%   [12]   
21     nl_21                          |                  0.0%   |                  0.0%   [13]   
------ ------------------------------ ------------------------- ------------------------- ------ 
macc=1,234,000 weights=36,860 act=13,760 ram_io=0
 
 Requested memory size by section - "stm32l4" target
 ------------------------------ -------- -------- ------- -------- 
 module                             text   rodata    data      bss 
 ------------------------------ -------- -------- ------- -------- 
 NetworkRuntime1020_CM4_GCC.a     30,220        0       0        0 
 network.o                           948    1,966   4,660      260 
 network_data.o                       48       16      88        0 
 lib (toolchain)*                  2,116        0       0        0 
 ------------------------------ -------- -------- ------- -------- 
 RT total**                       33,332    1,982   4,748      260 
 ------------------------------ -------- -------- ------- -------- 
 weights                               0   36,864       0        0 
 activations                           0        0       0   13,760 
 io                                    0        0       0        0 
 ------------------------------ -------- -------- ------- -------- 
 TOTAL                            33,332   38,846   4,748   14,020 
 ------------------------------ -------- -------- ------- -------- 
 *  toolchain objects (libm/libgcc*)
 ** RT AI runtime objects (kernels+infrastructure)
  
  Summary - "stm32l4" target
  ---------------------------------------------------
               FLASH (ro)      %*   RAM (rw)       % 
  ---------------------------------------------------
  RT total         40,062   52.1%      5,008   26.7% 
  ---------------------------------------------------
  TOTAL            76,926             18,768         
  ---------------------------------------------------
  *  rt/total


Generated files (7)
---------------------------------------------------------------- 
/home/bohdan/.stm32cubemx/network_output/network_data_params.h   
/home/bohdan/.stm32cubemx/network_output/network_data_params.c   
/home/bohdan/.stm32cubemx/network_output/network_data.h          
/home/bohdan/.stm32cubemx/network_output/network_data.c          
/home/bohdan/.stm32cubemx/network_output/network_config.h        
/home/bohdan/.stm32cubemx/network_output/network.h               
/home/bohdan/.stm32cubemx/network_output/network.c               
